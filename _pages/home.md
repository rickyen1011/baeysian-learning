---
layout: project
urltitle:  "Bayesian Learning in Speech and Language Processing"
title: "Celebrating 40 Years of Bayesian Learning in Speech and Language Processing"
categories: workshop, bayesian learning, machine learning, speech and natural language processing, 2021
permalink: /
bibtex: true
paper: true
acknowledgements: ""
---

<br>
<div class="row" id="dates">
  <div class="col-xs-12">
    <center><h1>Symposium for Celebrating 40 Years of Bayesian Learning in Speech and Language Processing and Beyond</h1></center>
    <center><h2>Taipei, ASRU, 2023</h2></center>
  </div>
</div>

<br />

<div class="row">
    <div class="col-xs-12">
        <p>
          Introduction
        </p>
    </div>
</div>


<br />

<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Tentative Schedule</h2>
  </div>
</div>

<br>
<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Historical Perspective & Beyond</td>
          <td>C.-H. Lee</td>
        </tr>
        <tr>
          <td>Online and Correlated HMMs</td>
          <td>Q. Huo</td>
        </tr>
        <tr>
          <td>Joint MAP of LR and HMMs</td>
          <td>T. K. Svendsen</td>
        </tr>
        <tr>
          <td>PVariational Bayesian Learning</td>
          <td>S. Watanabe</td>
        </tr>
        <tr>
          <td>Structural MAP for HMMs</td>
          <td>K. Shinoda</td>
        </tr>
        <tr>
          <td>MAP for N-grams and Beyond</td>
          <td>J.-T. Chien</td>
        </tr>
        <tr>
          <td>MAP for DNN Parameters</td>
          <td>S.M. Siniscalchi</td>
        </tr>
        <tr>
          <td>Panel Discussion</td>
          <td></td>
        </tr>
      </tbody>
    </table>
  </div>
</div>




<!--       <li><b>Unpublished work</b>: All submissions must be in PDF format. The submissions must be formated using the <a style="color:#2980b9;font-weight:400;" href="https://2021.naacl.org/calls/style-and-formatting/">NAACL 2021 LaTeX style file</a>. Submissions are limited to 4 content pages, including all figures and tables; additional pages containing statements of acknowledgements and funding disclosures, and references are allowed. The maximum file size for submissions is 50MB. The CMT-based review process will be double-blind to avoid potential conflicts of interests.</li>
    </ul>
    <p>
            In case of any issues, feel free to email the workshop organizers at: <a href="mailto:vigilworkshop@gmail.com">vigilworkshop@gmail.com</a>.
    </p>
    </div> -->
<!-- </div> -->

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>Target Audience</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <p>
      Researchers, graduate students, and practitioners who are interested in Quantum Circuit Learning with Basic Knowledge of linear algebra and neural network training (e.g., gradient and back-propagation).
      </p>
    <p>
      This tutorial aims to serve as a short lecture for researchers and students to access the emergent field of quantum neural networks from the viewpoint of the artificial intelligence community. The contents of this tutorial will provide sufficient backgrounds for participants to understand the motivation, research progress, opportunities, and ongoing challenges in quantum neural network-based speech and natural language processing. The outline of this tutorial is as follows:
    </p>
    <p>
          <ul>
  <li>I. Introduction and Motivation of Quantum Machine Learning and Quantum Computer </li>
  <li>Principles of Quantum Mechanics and Tensor Network Foundation;</li>
  <li>Introduction to Quantum Computing;</li>
  <li>Quantum Machine Learning and Quantum Neural Networks;</li>
  <li>II. The Fundamentals of Quantum Neural Networks </li>
  <li>III. The Applications of Quantum Neural Networks for Speech and Language Processing </li>
  <li>IV. Conclusion and Open Questions</li>
          </ul>
      </p><p>Anticipated target audience (introductory, intermediate, advanced) as well as expected number of attendees 
 Background:linear algebra, basic understanding of class neural networks for speech recognition and natural language processing. All technical details will be provided with references and clear illustration and explanation. 
</p><p>We will provide Quantum Simulation Support and hands-on exercise through an open-source repository for the audience base on 5 qubits IBM Q devices.  </p>
  </div>
</div>
<hr />



<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Honorary Committee Chair</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-3">
    <a href="https://chl.ece.gatech.edu/">
      <img class="people-pic" src="{{ "https://rickyen1011.github.io/bayesian-learning/static/img/people/chl.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://chl.ece.gatech.edu/">Chin-Hui Lee</a>
      <h6>Georgia Institute of Technology</h6>
    </div>
  </div>
</div>

<hr />

<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-3">
    <a href="https://www.microsoft.com/en-us/research/people/jinyli/">
      <img class="people-pic" src="{{ "https://rickyen1011.github.io/bayesian-learning/static/img/people/jinyu.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.microsoft.com/en-us/research/people/jinyli/">Jinyu Li</a>
      <h6>Microsoft Research</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-3">
    <a href="https://huckiyang.github.io/">
      <img class="people-pic" src="{{ "https://rickyen1011.github.io/bayesian-learning/static/img/people/huck.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://huckiyang.github.io/">Chao-Han Huck Yang</a>
      <h6>Georgia Insititue of Technology</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-3">
    <a href="http://mi.eng.cam.ac.uk/~cz277/">
      <img class="people-pic" src="{{ "https://rickyen1011.github.io/bayesian-learning/static/img/people/chao.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://mi.eng.cam.ac.uk/~cz277/">Chao Zhang</a>
      <h6>Google</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-3">
    <a href="[http://mi.eng.cam.ac.uk/~cz277](https://homepage.iis.sinica.edu.tw/pages/whm/index_en.html)/">
      <img class="people-pic" src="{{ "https://rickyen1011.github.io/bayesian-learning/static/img/people/wang.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="[http://mi.eng.cam.ac.uk/~cz277/](https://homepage.iis.sinica.edu.tw/pages/whm/index_en.html)">Hsin-Min Wang</a>
      <h6>Academia Sinica</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-3">
    <a href="[http://mi.eng.cam.ac.uk/~cz277/](https://scholar.google.com/citations?user=ZO5e5I4AAAAJ&hl=zh-TW)">
      <img class="people-pic" src="{{ "https://rickyen1011.github.io/bayesian-learning/static/img/people/tsao.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="[http://mi.eng.cam.ac.uk/~cz277/](https://scholar.google.com/citations?user=ZO5e5I4AAAAJ&hl=zh-TW)">Yu Tsao</a>
      <h6>Academia Sinica</h6>
    </div>
  </div>
</div> 

<!--
<hr />
<div class="row" id="intro">
    <div class="col-xs-12">
        <h2>Introduction</h2>
        <p>The research of quantum machine learning is an emerging field that has flourished with the rapid development of quantum computing. In particular, quantum neural networks (QNNs), similar to classical neural networks, have already been applied in many large-scale machine learning tasks such as automatic speech recognition, speech enhancement, and natural language understanding. Despite the hardware limitation on noisy intermediate-scale quantum (NISQ) devices (5–50 qubits), the QNN based deep architectures, such as a randomized quantum convolutional neural network (QCNN) and variational quantum circuit (VQC), can be set up to attain competitive empirical results in experiments of speech and language processing. Moreover, more secured data privacy can be ensured by applying QNN based models.</p>
        <p>Through IJCAI’s flagship and influence in AI research, we believe this tutorial can create the synergies and reinforce the momentum in advanced research and novel applications based on quantum computing and machine learning. This tutorial will provide an overview of the fundamentals of quantum mechanics, quantum machine learning and quantum neural networks. Then, we introduce the related applications in speech recognition and natural language understanding. In more detail, in the introduction part, we briefly introduce basic concepts of quantum computing, quantum mechanics and necessary multi-linear algebra associated with quantum technology. In the second section, we will discuss QNNs, especially based on variational quantum circuits (VQC) for QNNs. Finally, we provide several examples of employing VQC-QNN for speech recognition and natural language understanding.</p>
    </div>
</div>
-->

<hr />
     
<!-- CfP -->
<!--
<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Call for Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      The workshop welcomes papers on a range of topics related but not limited to:
    </p>
    <p>
          <ul>
  <li>Adaptors and adaptation;</li>
  <li>Efficient parameter tuning;</li>
  <li>Bayesian inference;</li>
  <li>Zero shot and few shot learning;</li>
  <li>Self supervised learning and data-efficient fine-tuning;</li>
  <li>Instruction tuning;</li>
  <li>In context learning;</li>
  <li>Chain of thoughts;</li>
  <li>Out of distributions;</li>
  <li>Bayesian approaches for uncertainty estimation;</li>
          </ul>
      </p>
  </div>
</div>
-->

<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Publications</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      All contributions to this Bayesian Celebration Workshop can be summarized in an abstract (limited to 200 words) to be published in the ASRU2023 Workshop Proceedings, 12-15 poster contributions with relevant topics to Bayesian Learning will be selected from submissions and reviewed by the Organizers (Call for Contributions will be sent to all potential participants and published in the ASRU website soon). Presentation materials, including 1-page summary or posters with references will be published in a symposium page hyperlinked to ASRU website.
    </p>
  </div>
</div>

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>References</h2>
  </div>
</div>
<div class="row">
  <div class="col-md-12">
    <ol>
      <li>P. Brown, Chin-Hui Lee, and J. Spohrer, "Bayesian adaptation in speech recognition," ICASSP, 1983.</li>
      <li>Qiang Huo, and Chin-Hui Lee "On-line adaptive learning of the continuous density hidden Markov model based on approximate recursive Bayes estimate," IEEE Transactions on Speech and Audio Processing 5.2 (1997): 161-172.</li>
      <li>Koichi Shinoda, and Chin-Hui Lee "A structural Bayes approach to speaker adaptation," IEEE Transactions on Speech and Audio Processing 9.3 (2001): 276-287.</li>
      <li>Shinji Watanabe, Yasuhiro Minami, Atsushi Nakamura, and Naonori Ueda, "Application of Variational Bayesian Approach to Speech Recognition," NIPS, 2002.</li>
      
    </ol>
  </div>
</div>


<div class="text-center p-3" style="background-color: rgba(0, 0, 0, 0)">
    <h6>Website theme is modified and inspired from the <a href="https://github.com/vigilworkshop/vigilworkshop.github.io">VIGIL workshop Series</a>. Florian S. et al. </h6>
  </div>
